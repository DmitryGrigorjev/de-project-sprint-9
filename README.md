# Проект 9-го спринта

### Как работать с репозиторием
1. В вашем GitHub-аккаунте автоматически создастся репозиторий `de-project-sprint-9` после того, как вы привяжете свой GitHub-аккаунт на Платформе.
2. Скопируйте репозиторий на свой компьютер. В качестве пароля укажите ваш `Access Token`, который нужно получить на странице [Personal Access Tokens](https://github.com/settings/tokens)):
	* `git clone https://github.com/{{ username }}/de-project-sprint-9.git`
3. Перейдите в директорию с проектом: 
	* `cd de-project-sprint-9`
4. Выполните проект и сохраните получившийся код в локальном репозитории:
	* `git add .`
	* `git commit -m 'my best commit'`
5. Обновите репозиторий в вашем GitHub-аккаунте:
	* `git push origin main`
	
### Выполнение проекта
# DDS слой 

1. Не очень понятно написано в задании, но насколько я понял - данные из брокера уже лежат в stg слое после выполнения заданий спринта, за одним исключением -
	как и говорилось в ходе спринта названия ресторана нет, только uuid. Поэтому в ходе проекта будем обогащать данные в dds 
	слое из редиса (где кстати из всех данных всего один ресторан) и разносить
	по таблицам dds слоя разбирая json из поля paylod в таблице stg слоя (а не забирать все и обогащать из kafka). Скриншоты данных - redis.png и stg_postgre.png.

2. Добавлен файл redis_client.py (service_dds\src\lib\redis) для подключения к redis и внесены изменения в service_dds\src\app_config.py (убрано все что касается kafka).
	Также внесены правки в прочие конфигурационные файлы по необходимости.

3. Схема данных dds слоя не соответствует тому что получилось выгрузить из редиса. Кое где косяки и не было смысла делать суррогатные ключи таблиц-хабов типа uuid. Больше 
	подошел бы автоинкремент. А вот для связок уже можно использовать uuid (для сущности order его можно подставить из object_id, но там не uuid). В общем грусть оттого что
	схема dds проектировалась по учебнику спринта. И даже uuid там не uuid (см. скриншоты, должно быть что то вроде a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11).
	Вссе это можно обработать напильником, но по моему это выйдет за рамки проекта. В остальном - приблизительно одинаковое
	вытаскивание данных из редиса и разнесение этого в постгри, а также вытаскивание данных из stg постгри и разнесение по таблицам  DDS слоя.
	
4. Запушено в yandex-cloud - cr.yandex/crp1ihf9a8emk9sn50du/dds_service

# CDM слой

1. Здесь логика менее насыщенная и данные в dds слое "чистые". Два несложных запроса в cdm_repository.py заполняют витрины данных, предварительно при инициализации двух
	других классов витрины очищаются.
2. аналогично - cr.yandex/crp1ihf9a8emk9sn50du/cdm_service

# Вроде бы все. по DataLens не стал делать визуализацию, она не обязательна :)
